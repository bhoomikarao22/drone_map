{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26e3444-63dd-4b38-bc36-b5f5d14e4ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def extract_frames(video_path, output_path, frame_interval):\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    while True:\n",
    "        success, frame = video.read()\n",
    "\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_interval == 0:\n",
    "            output_file = f\"{output_path}/frame_{frame_count}.jpg\"\n",
    "            # Save the frame with high quality (100 for max quality)\n",
    "            cv2.imwrite(output_file, frame, [cv2.IMWRITE_JPEG_QUALITY, 100])\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "        for _ in range(frame_interval - 1):\n",
    "            video.read()\n",
    "\n",
    "    video.release()\n",
    "\n",
    "video_path = \"sample.mp4\"  \n",
    "output_path = \"frames\"  \n",
    "frame_interval = 5\n",
    "extract_frames(video_path, output_path, frame_interval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7672164-2bf1-4ad7-8ddc-307931a5f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "path = \"frames\"\n",
    "\n",
    "def crop_to_largest_rectangle(image):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Threshold the image to create a binary mask of non-black regions\n",
    "    _, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours of the non-black areas\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Get the bounding box of the largest contour (assuming it's the stitched region)\n",
    "    x, y, w, h = cv2.boundingRect(contours[0])\n",
    "    \n",
    "    # Crop the image to the bounding box\n",
    "    cropped = image[y:y+h, x:x+w]\n",
    "    \n",
    "    return cropped\n",
    "\n",
    "def combining(directory):\n",
    "    sift = cv2.SIFT_create()\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "\n",
    "    image_files = [f for f in os.listdir(directory) if f.endswith('.png') or f.endswith('.jpg')]\n",
    "    image_files.sort()\n",
    "\n",
    "    def stitch_images(images):\n",
    "        img1 = images[0]\n",
    "        count = 0\n",
    "\n",
    "        for img2 in images[1:]:\n",
    "            kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "            kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "            if des1 is not None and des2 is not None and des1.dtype == des2.dtype:\n",
    "                matches = bf.match(des1, des2)\n",
    "            else:\n",
    "                print(\"Descriptors are either empty or have different types.\")\n",
    "                continue\n",
    "\n",
    "            matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "            if len(matches) > 1:\n",
    "                count += 1\n",
    "                src_pts = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "                dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "                M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "                h1, w1 = img1.shape[:2]\n",
    "                h2, w2 = img2.shape[:2]\n",
    "                points = np.float32([[0, 0], [0, h1], [w1, h1], [w1, 0]]).reshape(-1, 1, 2)\n",
    "                dst = cv2.perspectiveTransform(points, M)\n",
    "                raw_points = np.float32([[0, 0], [0, h2], [w2, h2], [w2, 0]]).reshape(-1, 1, 2)\n",
    "                all_points = np.concatenate((dst, raw_points), axis=0)\n",
    "\n",
    "                [xmin, ymin] = np.int32(all_points.min(axis=0).ravel() - 0.5)\n",
    "                [xmax, ymax] = np.int32(all_points.max(axis=0).ravel() + 0.5)\n",
    "                tform_width = xmax - xmin\n",
    "                tform_height = ymax - ymin\n",
    "\n",
    "                tform = np.array([[1, 0, -xmin], [0, 1, -ymin], [0, 0, 1]])\n",
    "                panorama = cv2.warpPerspective(img1, tform.dot(M), (tform_width, tform_height))\n",
    "\n",
    "                xstart = max(-xmin, 0)\n",
    "                ystart = max(-ymin, 0)\n",
    "                xend = min(xstart + img2.shape[1], panorama.shape[1])\n",
    "                yend = min(ystart + img2.shape[0], panorama.shape[0])\n",
    "\n",
    "                panorama[ystart:yend, xstart:xend] = img2\n",
    "                img1 = panorama\n",
    "\n",
    "            else:\n",
    "                print(\"Not enough matches are found between images.\")\n",
    "\n",
    "        return img1\n",
    "\n",
    "    # Group the images into batches of 3\n",
    "    image_batches = [image_files[i:i+3] for i in range(0, len(image_files), 3)]\n",
    "\n",
    "    # Stitch images in each batch and collect the results\n",
    "    results = [stitch_images([cv2.imread(os.path.join(directory, f)) for f in batch]) for batch in image_batches]\n",
    "\n",
    "    # Finally, stitch together the results\n",
    "    final = stitch_images(results)\n",
    "\n",
    "    # Crop the final result to remove black regions and ensure a rectangular output\n",
    "    final_cropped = crop_to_largest_rectangle(final)\n",
    "\n",
    "    cv2.imwrite('final_result.jpg', final_cropped)\n",
    "\n",
    "combining(path)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6ff89-90c4-4e0e-b90e-12e228da2a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cfc11f-8dd3-4f55-9b3c-88396fea38f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
